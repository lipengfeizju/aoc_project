#ifndef FLA_DPM_DETECTOR_CPP_
#define FLA_DPM_DETECTOR_CPP_

#include "ffld_ros/fla_dpm_detector.h"

namespace fla_dpm_detector {
FlaDpmDetector::FlaDpmDetector(ros::NodeHandle nh_in, int param_option,
                               double starting_distance_in, bool debug,
			       sensor_msgs::CameraInfo cinfo_left_in,
			       sensor_msgs::CameraInfo cinfo_right_in)
  : dpm_client(nh_in), it(nh_in), block_matcher_(cv::StereoBM::FISH_EYE_PRESET) {

  nh = nh_in;

  cinfo_left = cinfo_left_in;
  cinfo_right = cinfo_right_in;

  image_pub = it.advertise("detections", 1);
  pub_rect_left_ = it.advertise("left_rect", 1);
  pub_rect_right_ = it.advertise("right_rect", 1);
  pose_pub = nh.advertise<geometry_msgs::PoseStamped>("polaris_pos", 1);
  disp_pub = nh.advertise<stereo_msgs::DisparityImage>("disparity", 1);

  dpm_detect_client::Params params;

  params.model_num = param_option;
  params.overlap = 0.5;
  params.threshold = -0.5;
  params.padding = 6;
  params.interval = 3;
  params.resize_val = 0.5;
  rate = 1;

  num_ima = 0;

  /*if (param_option == 1) {
    params.model_num = 0;
    params.overlap = 0.5;
    params.threshold = -0.5;
    params.padding = 6;
    params.interval = 3;
    params.resize_val = 0.5;
    rate = 1;
  } else {
    params.model_num = 0;
    params.overlap = 0.5;
    params.threshold = -0.5;
    params.padding = 6;
    params.interval = 3;
    params.resize_val = 0.5;
    rate = 1;
    }*/
  
  resize_val = params.resize_val;
  
  dpm_client.setDpmParams(params);

  starting_distance = starting_distance_in;

  block_matcher_.state->SADWindowSize = 11;
  block_matcher_.state->numberOfDisparities = 32;
  block_matcher_.state->preFilterSize = 5;
  block_matcher_.state->preFilterCap = 25;
  block_matcher_.state->minDisparity = 0;
  block_matcher_.state->textureThreshold = 100;
  block_matcher_.state->uniquenessRatio = 30;
  block_matcher_.state->speckleWindowSize = 100;
  block_matcher_.state->speckleRange = 1;
  block_matcher_.state->disp12MaxDiff = 0;
  /*cv::namedWindow("Left", 0);
  cv::namedWindow("Right", 0);
  cv::namedWindow("Disparity", 0);
  */

  if (!debug) {
    geometry_msgs::PoseStamped::ConstPtr goal_in =
      ros::topic::waitForMessage<geometry_msgs::PoseStamped>("goal_pose", nh);
    goal_pose = goal_in->pose;
    cam_odom_sub = nh.subscribe("cam_odom", 1, &FlaDpmDetector::odomCb, this);
  } else {
    printf("Starting cameras\n");
    startImageSub();
  }
}

  void FlaDpmDetector::odomCb(const nav_msgs::Odometry::ConstPtr &odom_in) {
    cam_odom_pose = odom_in->pose.pose;
    if (sqrt(pow(cam_odom_pose.position.x - goal_pose.position.x, 2) +
	     pow(cam_odom_pose.position.y - goal_pose.position.y, 2) +
	     pow(cam_odom_pose.position.z - goal_pose.position.z, 2))) {
      //image_sub = nh.subscribe<sensor_msgs::Image>("image", 1,
      //&FlaDpmDetector::imgCb, this);

      startImageSub();
      //odom_sub.shutdown();
      // goal_sub.unregister();
    }
  }

  /*void FlaDpmDetector::goalCb(const geometry_msgs::PoseStamped::ConstPtr
    &goal_in) {
    goal_pose = goal_in->pose;
    }*/

  void FlaDpmDetector::startImageSub(){
    exact_sync_.reset( new ExactSync(ExactPolicy(5),
                                     sub_l_image_,// sub_l_info_,
                                     sub_r_image_));//, sub_r_info_) );
    exact_sync_->registerCallback(boost::bind(&FlaDpmDetector::imgCb,
                                              this, _1, _2/*, _3, _4*/));
    sub_l_image_.subscribe(it, "left/image_raw", 1);
    //sub_l_info_.subscribe(nh, "left/camera_info", 1);
    sub_r_image_.subscribe(it, "right/image_raw", 1);
    //sub_r_info_.subscribe(nh, "right/camera_info", 1);
    
  }

  void FlaDpmDetector::imgCb(const sensor_msgs::ImageConstPtr& l_image_msg,
			     //const sensor_msgs::CameraInfoConstPtr& l_info_msg,
			     const sensor_msgs::ImageConstPtr& r_image_msg) {
			     //const sensor_msgs::CameraInfoConstPtr& r_info_msg) {    
    ROS_INFO("[fla_dpm_detector]: Images received");

    
    Eigen::Vector2d focalLength_l(606.7306364868343, 606.1953022153633);
    Eigen::Vector2d principalPoint_l(642.2415607219831, 496.56331597969194);
    Eigen::Vector2i resolution_l(1280, 1024);
    Eigen::Vector4d distCoeffs_Equi_l(-0.015397030690855976, -0.0010907469061702843, -0.0014083386408710616, 0.0002646077335247587);

    undistorter::PinholeGeometry camera_l(focalLength_l, principalPoint_l, resolution_l, undistorter::EquidistantDistortion::create(distCoeffs_Equi_l));
    
    undistorter::PinholeUndistorter undistorter_l(camera_l, 1.0, 1.0, cv::INTER_LINEAR);
					      
    Eigen::Vector2d focalLength_r(605.0070213469199, 604.6659820543365);
    Eigen::Vector2d principalPoint_r(632.8515448979249, 513.1367247174866);
    Eigen::Vector2i resolution_r(1280, 1024);
    Eigen::Vector4d distCoeffs_Equi_r(-0.01135575563431574, -0.011222698900445808, 0.007114751598544675, -0.002106551680412531);

    undistorter::PinholeGeometry camera_r(focalLength_r, principalPoint_r, resolution_r, undistorter::EquidistantDistortion::create(distCoeffs_Equi_r));
    
    undistorter::PinholeUndistorter undistorter_r(camera_r, 1.0, 1.0, cv::INTER_LINEAR);


    cv::Mat image_left = cv_bridge::toCvCopy(l_image_msg)->image;;
    cv::Mat image_right = cv_bridge::toCvCopy(r_image_msg)->image;;
    cv::Mat rect_left, rect_right;

    /*
    double f = cinfo_left.P[0];
    double b = -cinfo_right.P[3]/f;
    double cx = cinfo_left.P[2];
    double cy = cinfo_left.P[6];
    
    for (int i=0;i<5;i++){
      cinfo_left.D[i] = 0;
      cinfo_right.D[i] = 0;
    }
    
    left_model_.fromCameraInfo(cinfo_left);
    right_model_.fromCameraInfo(cinfo_right);
    */
    cv::Mat_<double> d_l(5,1);
    cv::Mat_<double> d_r(5,1);
    d_l << 0,0,0,0,0;
    d_r << 0,0,0,0,0;
    
    Eigen::Matrix3d R;
    R << 0.999947104845898, -0.00801301760947058, 0.0064481826197725, 0.00795530117981756, 0.999928506404327,0.0089272203484522, -0.00651925558986723, -0.00887545090695341, 0.999939361000332;
    Eigen::Vector3d t;
    t << -0.199690397339566,-0.000300843449172252,0.000547582273394725;
    
    cv::Mat Rcv, tcv;
    cv::eigen2cv(R,Rcv);
    cv::eigen2cv(t,tcv);
    
    cv::Mat R_l, R_r, P_l, P_r, Q;

    // Rectify!
    Eigen::Matrix3d optimal_l = undistorter::cv_helper::getOptimalNewCameraMatrix(camera_l, cvSize(1280,1024), 0.0, cvSize(1280, 1024));
    Eigen::Matrix3d optimal_r = undistorter::cv_helper::getOptimalNewCameraMatrix(camera_r, cvSize(1280,1024), 0.0, cvSize(1280, 1024));

    cv::Mat mapX_l, mapY_l, mapX_r, mapY_r;
    undistorter::cv_helper::initUndistortRectifyMap(camera_l, Eigen::Matrix3d::Identity(), optimal_l, cv::Size(1280,1024), CV_32FC1, mapX_l, mapY_l);
    undistorter::cv_helper::initUndistortRectifyMap(camera_r, Eigen::Matrix3d::Identity(), optimal_r, cv::Size(1280,1024), CV_32FC1, mapX_r, mapY_r);

    cv::remap(image_left, image_left, mapX_l, mapY_l, cv::INTER_LINEAR);
    cv::remap(image_right, image_right, mapX_r, mapY_r, cv::INTER_LINEAR);
    
    cv::Mat K_l, K_r;
    
    cv::eigen2cv(optimal_l, K_l);
    cv::eigen2cv(optimal_r, K_r);

    /*cv::Mat_<double> K_l(3,3);
    cv::Mat_<double> K_r(3,3);
    K_l << focalLength_l[0], 0, principalPoint_l[0], 0, focalLength_l[1], principalPoint_l[1],0,0,1;
    K_r << focalLength_r[0], 0, principalPoint_r[0], 0, focalLength_r[1], principalPoint_r[1],0,0,1;*/
    
    cv::stereoRectify(K_l, d_l, K_r, d_r, cv::Size(1280,1024), Rcv, tcv, R_l, R_r, P_l, P_r, Q);

    double f = P_l.at<double>(cv::Point(0,0));
    double b = -P_r.at<double>(cv::Point(3,0))/f;
    double cx = P_l.at<double>(cv::Point(2,0));
    double cy = P_l.at<double>(cv::Point(2,1));

    cv::initUndistortRectifyMap(K_l, d_l, R_l, P_l, cv::Size(1280, 1024), CV_32FC1, mapX_l, mapY_l);
    cv::initUndistortRectifyMap(K_r, d_r, R_r, P_r, cv::Size(1280, 1024), CV_32FC1, mapX_r, mapY_r);
    
    cv::remap(image_left, rect_left, mapX_l, mapY_l, cv::INTER_LINEAR);
    cv::remap(image_right, rect_right, mapX_r, mapY_r, cv::INTER_LINEAR);
    
    std::ostringstream oss2;
    oss2 << "/home/alex/FLA_git/data/left_" << num_ima << ".png";
    std::string left_var = oss2.str();
    std::ostringstream oss3;
    oss3 << "/home/alex/FLA_git/data/right_" << num_ima << ".png";
    std::string right_var = oss3.str(); 
    
    cv::imwrite(left_var, rect_left);
    cv::imwrite(right_var, rect_right);

    num_ima++;

    ros::Time detect_start = ros::Time::now();

    cv_bridge::CvImage rect_left_msg;
    rect_left_msg.header = l_image_msg->header;
    rect_left_msg.image = rect_left;
    rect_left_msg.encoding = l_image_msg->encoding;

    // Call detection on left image only
    ffld_ros::DetectObject detections = dpm_client.requestDetection(*(rect_left_msg.toImageMsg()));
    
    ROS_INFO("[fla_dpm_detector]: dpm detection took %f seconds\n", (ros::Time::now()-detect_start).toSec());

    // Publish detection image
    if (image_pub.getNumSubscribers() > 0) {
      cv::Mat detection_image = dpm_client.drawDetection(rect_left, detections);
      image_pub.publish(cv_bridge::CvImage(l_image_msg->header, "bgr8",
					   detection_image).toImageMsg());
    }

    // If no detection, just return
    if (detections.response.left.size()==0) {
      return;
    }   

    double center_x = (detections.response.left[0]+detections.response.right[0])/(resize_val*2);
    double center_y = (detections.response.top[0]+detections.response.bottom[0])/(resize_val*2);

    center_x = (center_x-cx)/f;
    center_y = (center_y-cy)/f;
 
    sensor_msgs::RegionOfInterest roi;
    int x_offset = std::max(round(detections.response.left[0]/resize_val), 1.0);
    int y_offset = std::max(round(detections.response.top[0]/resize_val), 1.0);
    int height = round((detections.response.bottom[0] - detections.response.top[0])/resize_val);
    int width = round((detections.response.right[0] - detections.response.left[0])/resize_val);
    
    bool istop = false;
    bool isleft = false;

    if (x_offset - block_matcher_.state->SADWindowSize >0){
      x_offset -= block_matcher_.state->SADWindowSize;
      isleft = true;
    } 
    width += block_matcher_.state->SADWindowSize;
    
    if (y_offset-block_matcher_.state->SADWindowSize > 0){
      y_offset -= block_matcher_.state->SADWindowSize;
      istop = true;
    } 
    height += block_matcher_.state->SADWindowSize;
    
    cv::Rect detectROI(x_offset, y_offset, width, height);
    
    // Crop image to detection ROI                                                                                                                         
    rect_left = rect_left(detectROI);
    rect_right = rect_right(detectROI);
    
    //cv::Mat_<int16_t> disp_image(rect_left.rows, rect_left.cols);
    cv::Mat disp_image;
    
    ros::Time disp_start = ros::Time::now();

    block_matcher_(rect_left, rect_right, disp_image, CV_32F);
       
    
    if (isleft) {
      x_offset = block_matcher_.state->SADWindowSize+1;
      width = disp_image.cols - x_offset;
    } else {
      x_offset = 1;
      width = disp_image.cols - x_offset - block_matcher_.state->SADWindowSize;
    }

    if (istop) {
      y_offset = block_matcher_.state->SADWindowSize+1;
      height = disp_image.rows - y_offset;
    } else {
      y_offset = 1;
      height = disp_image.rows - y_offset - block_matcher_.state->SADWindowSize;
    }

    cv::Rect roi2(x_offset, y_offset, width, height);
    /*
    disp_image = disp_image(detectROI);
    rect_left = rect_left(detectROI);
    rect_right = rect_right(detectROI);*/
    //disp_image = disp_image(roi2);

    double maxVal;
    cv::Point maxLoc;
    
    cv::minMaxLoc(disp_image, 0, &maxVal, 0, &maxLoc);

    if (maxVal <= 0){
      return;
    }

    double depth = f*b/maxVal;

    tf::Transform cam_odom;
    cam_odom.setOrigin(tf::Vector3(cam_odom_pose.position.x, cam_odom_pose.position.y, cam_odom_pose.position.z));
    cam_odom.setRotation(tf::Quaternion(cam_odom_pose.orientation.x, cam_odom_pose.orientation.y, cam_odom_pose.orientation.z, cam_odom_pose.orientation.w));
    cam_odom_vec.push_back(cam_odom);

    tf::Transform polaris_pos;
    polaris_pos.setOrigin(tf::Vector3(center_x*depth, center_y*depth, depth));
    polaris_pos.setRotation(tf::Quaternion(0,0,0,1));
    polaris_pos_vec.push_back(polaris_pos);

    geometry_msgs::PoseStamped posemsg;
    geometry_msgs::Pose pose;
    pose.position.x = center_x*depth;
    pose.position.y = center_y*depth;
    pose.position.z = depth;
    pose.orientation.w = 1;
    posemsg.pose = pose;
    posemsg.header.stamp = ros::Time::now();
    posemsg.header.frame_id = l_image_msg->header.frame_id;

    pose_pub.publish(posemsg);
    /*
    std::ostringstream oss;
    oss << "/home/alex/FLA_git/data/disparity_" << num_ima << ".png";
    std::string var = oss.str();
    std::ostringstream oss2;
    oss2 << "/home/alex/FLA_git/data/left_" << num_ima << ".png";
    std::string left_var = oss2.str();
    
    std::ostringstream oss3;
    oss3 << "/home/alex/FLA_git/data/right_" << num_ima << ".png";
    std::string right_var = oss3.str(); 
    cv::imwrite(var, disp_image);
    cv::imwrite(left_var, rect_left);
    cv::imwrite(right_var, rect_right);
    
    num_ima++;
    */
    
    //publish();

    ROS_INFO("[fla_dpm_detector]: Time for disparity matching is: %f\n", (ros::Time::now()-disp_start).toSec());    
    
    cv::circle(rect_left, maxLoc, 5, cv::Scalar(255), 3);

    cv::normalize(disp_image, disp_image, 0, 255, CV_MINMAX, CV_8U);
    
    cv::imshow("Left", rect_left);
    cv::imshow("Right", rect_right);
    cv::imshow("Disparity", disp_image);
    cv::waitKey(10);
  }

  void FlaDpmDetector::publish() {
    if (valid_pose.size()==0){
      valid_pose.push_back(true);
      return;
    }
    
    int num_match = 0;
    int num_valid = 0;

    tf::Transform curr_pos = polaris_pos_vec.back();

    for (int i=0; i<valid_pose.size(); i++){
      if (valid_pose[i]) {
	tf::Vector3 transformed_pos = (cam_odom_vec[i].inverseTimes(curr_pos)).getOrigin();
	tf::Vector3 orig_pos = polaris_pos_vec[i].getOrigin();
	double transform_error = transformed_pos.distance(orig_pos);
	if (transform_error < error_tol) {
	  num_match++;
	}
	num_valid++;
      }
    }
    
  }

  FlaDpmDetector::~FlaDpmDetector() {}
}

int main(int argc, char **argv) {
  ros::init(argc, argv, "fla_dpm_detector");
  
  ros::NodeHandle nh;
  ros::NodeHandle nh_priv("~");

  double starting_distance;
  int param_option;
  bool debug;
  std::string cinfo_left_url, cinfo_right_url;
  nh_priv.param<double>("starting_distance", starting_distance);
  nh_priv.param<int>("detection_mode", param_option, 1);
  nh_priv.param<bool>("debug", debug, true);

  /*nh_priv.getParam("cinfo_left_url", cinfo_left_url);
    nh_priv.getParam("cinfo_right_url", cinfo_right_url);

  camera_info_manager::CameraInfoManager cam_man(nh);
  sensor_msgs::CameraInfo cinfo_left, cinfo_right;    

  cam_man.setCameraName("cam0");
  if (cam_man.validateURL(cinfo_left_url)){
    cam_man.loadCameraInfo(cinfo_left_url);
    cinfo_left = cam_man.getCameraInfo();
  } else {
    ROS_ERROR("[fla_dpm_detector]: Error, camera info left URL is incorrect: %s", cinfo_left_url.c_str());
  }

  cam_man.setCameraName("cam1");
  if (cam_man.validateURL(cinfo_right_url)){
    cam_man.loadCameraInfo(cinfo_right_url);
    cinfo_right = cam_man.getCameraInfo();
  } else {
    ROS_ERROR("[fla_dpm_detector]: Error, camera info right URL is incorrect: %s", cinfo_right_url.c_str());
    }*/

  fla_dpm_detector::FlaDpmDetector detector(nh, param_option,
                                            starting_distance, debug);
  ros::Rate loop_rate(detector.rate);

  while (ros::ok()) {
    ros::spinOnce();
    loop_rate.sleep();
  }
}
#endif
